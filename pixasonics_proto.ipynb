{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import signalflow as sf\n",
    "from PIL import Image\n",
    "from IPython.display import Audio, display\n",
    "from pixasonics.core import App, Mapper\n",
    "from pixasonics.features import MeanPixelValue\n",
    "from pixasonics.synths import Theremin\n",
    "\n",
    "# Create app\n",
    "app = App()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image\n",
    "img_path = \"images/cellular_dataset/merged_8bit/Timepoint_005_220518-ST_C03_s1.jpg\"\n",
    "# img_path = \"images/test.jpg\"\n",
    "img = app.load_image_file(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image as a numpy array\n",
    "img_path = \"images/cellular_dataset/merged_8bit/Timepoint_005_220518-ST_C03_s1.jpg\"\n",
    "img = Image.open(img_path)\n",
    "img = np.array(img)\n",
    "app.load_image_data(img) # load as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load HDR images\n",
    "img_path = \"images/cellular_dataset/single_channel_16bit/Timepoint_005_220518-ST_C03_s1_w1.TIF\"\n",
    "app.load_image_file(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine two HDR images and load as numpy array\n",
    "img_path = \"images/cellular_dataset/single_channel_16bit/Timepoint_005_220518-ST_C03_s1_w2.TIF\"\n",
    "img_path2 = \"images/cellular_dataset/single_channel_16bit/Timepoint_005_220518-ST_C03_s1_w1.TIF\"\n",
    "img = Image.open(img_path)\n",
    "img2 = Image.open(img_path2)\n",
    "img = np.array(img)\n",
    "img2 = np.array(img2)\n",
    "img = np.stack([img, img2], axis=-1)\n",
    "print(img.shape)\n",
    "app.load_image_data(img) # load as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all red-ch images into arrays and concatenate them in the channel dimension\n",
    "img_folder = \"images/cellular_dataset/single_channel_16bit/\"\n",
    "img_files = os.listdir(img_folder)\n",
    "img_files = [f for f in img_files if f.endswith(\"w2.TIF\")] # only red channel images\n",
    "imgs = []\n",
    "for img_file in img_files:\n",
    "    img_path = os.path.join(img_folder, img_file)\n",
    "    img = Image.open(img_path)\n",
    "    img = np.array(img)\n",
    "    imgs.append(img)\n",
    "img = np.stack(imgs, axis=-1) # now the last dimension is the channel dimension\n",
    "print(img.shape)\n",
    "app.load_image_data(img) # load as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all red-ch images into arrays and concatenate them in the layer dimension\n",
    "img_folder = \"images/cellular_dataset/single_channel_16bit/\"\n",
    "img_files = os.listdir(img_folder)\n",
    "img_files = [f for f in img_files if f.endswith(\"w2.TIF\")] # only red channel images\n",
    "imgs = []\n",
    "for img_file in img_files:\n",
    "    img_path = os.path.join(img_folder, img_file)\n",
    "    img = Image.open(img_path)\n",
    "    img = np.array(img)[..., None] # add a new dimension for channels\n",
    "    imgs.append(img)\n",
    "img = np.stack(imgs, axis=-1) # now the last dimension is the layer dimension\n",
    "print(img.shape)\n",
    "app.load_image_data(img) # load as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine red and green channels and all layers\n",
    "img_folder = \"images/cellular_dataset/single_channel_16bit/\"\n",
    "img_files = os.listdir(img_folder)\n",
    "imgs_red = [f for f in img_files if f.endswith(\"w2.TIF\")] # only red channel images\n",
    "imgs_green = [f for f in img_files if f.endswith(\"w1.TIF\")] # only green channel images\n",
    "imgs = []\n",
    "for img_red, img_green in zip(imgs_red, imgs_green):\n",
    "    img_path_red = os.path.join(img_folder, img_red)\n",
    "    img_path_green = os.path.join(img_folder, img_green)\n",
    "    img_red = Image.open(img_path_red)\n",
    "    img_green = Image.open(img_path_green)\n",
    "    img_red = np.array(img_red)\n",
    "    img_green = np.array(img_green)\n",
    "    img = np.stack([img_red, img_green], axis=-1) # now the last dimension is the channel dimension\n",
    "    imgs.append(img)\n",
    "img = np.stack(imgs, axis=-1) # now the last dimension is the layer dimension\n",
    "print(img.shape)\n",
    "app.load_image_data(img) # load as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use all images in the folder\n",
    "img_folder = \"images/cellular_dataset/single_channel_16bit/\"\n",
    "img_files = os.listdir(img_folder)\n",
    "imgs_red = [f for f in img_files if f.endswith(\"w2.TIF\")] # only red channel images\n",
    "imgs_green = [f for f in img_files if f.endswith(\"w1.TIF\")] # only green channel images\n",
    "imgs_blue = [f for f in img_files if f.endswith(\"w3.TIF\")] # only blue channel images\n",
    "imgs = []\n",
    "for img_red, img_green, img_blue in zip(imgs_red, imgs_green, imgs_blue):\n",
    "    img_path_red = os.path.join(img_folder, img_red)\n",
    "    img_path_green = os.path.join(img_folder, img_green)\n",
    "    img_path_blue = os.path.join(img_folder, img_blue)\n",
    "    img_red = Image.open(img_path_red)\n",
    "    img_green = Image.open(img_path_green)\n",
    "    img_blue = Image.open(img_path_blue)\n",
    "    img_red = np.array(img_red)\n",
    "    img_green = np.array(img_green)\n",
    "    img_blue = np.array(img_blue)\n",
    "    img = np.stack([img_red, img_green, img_blue], axis=-1) # now the last dimension is the channel dimension\n",
    "    imgs.append(img)\n",
    "img = np.stack(imgs, axis=-1) # now the last dimension is the layer dimension\n",
    "print(img.shape)\n",
    "app.load_image_data(img) # load as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.normalize_display = False\n",
    "app.normalize_display_global = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature\n",
    "mean_pix = MeanPixelValue()\n",
    "# mean_pix = MeanPixelValue(selected_channels=[0, 1]) # test selected channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.attach_feature(mean_pix)\n",
    "app.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synth\n",
    "# theremin = Theremin()\n",
    "theremin = Theremin(frequency=[440, 440], panning=[-1, 1]) # test multichannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.synths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.attach_synth(theremin)\n",
    "app.synths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapper\n",
    "pix2freq = Mapper(mean_pix, theremin[\"frequency\"], exponent=2, out_high=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.attach_mapper(pix2freq)\n",
    "app.mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.detach_mapper(pix2freq)\n",
    "app.mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test adding another mapping: mean pixel value to amplitude with an exponential curve\n",
    "pix2amp = Mapper(mean_pix, theremin[\"amplitude\"], exponent=2)\n",
    "app.attach_mapper(pix2amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix2pan = Mapper(mean_pix, theremin[\"panning\"])\n",
    "app.attach_mapper(pix2pan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detach a mapper\n",
    "app.detach_mapper(pix2amp)\n",
    "app.mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detach old frequency mapping and add a new one with different scaling\n",
    "app.detach_mapper(pix2freq)\n",
    "pix2freq = Mapper(mean_pix, theremin[\"frequency\"], exponent=2, out_low=100, out_high=2000)\n",
    "app.attach_mapper(pix2freq)\n",
    "app.mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = sf.AudioGraph.get_shared_graph()\n",
    "print(graph.structure)\n",
    "print(graph.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Real-Time Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: horizontal scan\n",
    "duration = 5\n",
    "my_timeline = [\n",
    "    (0, {\n",
    "        \"probe_width\": 1,\n",
    "        \"probe_height\": 500,\n",
    "        \"probe_x\": 0,\n",
    "        \"probe_y\": 0\n",
    "    }),\n",
    "    (duration, {\n",
    "        \"probe_x\": 499\n",
    "    })\n",
    "]\n",
    "\n",
    "target_filename = \"horizontal_scan.wav\"\n",
    "\n",
    "app.render_timeline_to_file(my_timeline, target_filename)\n",
    "\n",
    "display(Audio(target_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: vertical scan\n",
    "duration = 5\n",
    "my_timeline = [\n",
    "    (0, {\n",
    "        \"probe_width\": 500,\n",
    "        \"probe_height\": 1,\n",
    "        \"probe_x\": 0,\n",
    "        \"probe_y\": 0\n",
    "    }),\n",
    "    (duration, {\n",
    "        \"probe_y\": 499\n",
    "    })\n",
    "]\n",
    "\n",
    "target_filename = \"vertical_scan.wav\"\n",
    "\n",
    "app.render_timeline_to_file(my_timeline, target_filename)\n",
    "\n",
    "display(Audio(target_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Array reading proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(100, 100, 20, 10)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels = [0, 2, 5, 9]\n",
    "b = a[:, :, selected_channels, :]\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(a, axis=(1, 2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_16bit = \"images/cellular_dataset/single_channel_16bit/Timepoint_005_220518-ST_C03_s1_w1.TIF\"\n",
    "img = Image.open(path_16bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_8bit = \"images/cellular_dataset/merged_8bit/Timepoint_005_220518-ST_C03_s1.jpg\"\n",
    "img = Image.open(path_8bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the image dimensions\n",
    "width, height = img.size\n",
    "# get image channels\n",
    "channels = len(img.getbands())\n",
    "width, height, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the image data type\n",
    "img.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img)\n",
    "img.shape, img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the image is not dtype=uint8,divide it by the max of the dtype and convert to uint8\n",
    "img = (img / np.iinfo(img.dtype).max * 255).astype(np.uint8)\n",
    "img.shape, img.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.iinfo(np.uint16).max, np.iinfo(np.uint8).max, np.finfo(np.float32).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the max of float32\n",
    "np.finfo(np.float32).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get whether the img is integer or float dtype\n",
    "is_int = np.issubdtype(img.dtype, np.integer)\n",
    "is_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, target_width, target_height):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((target_width, target_height))\n",
    "    img_hires = np.array(img)\n",
    "    if np.issubdtype(img_hires.dtype, np.integer):\n",
    "        img_display = (img_hires / np.iinfo(img_hires.dtype).max * 255).astype(np.uint8)\n",
    "    else:\n",
    "        img_display = (img_hires / np.finfo(img_hires.dtype).max * 255).astype(np.uint8)\n",
    "    return img_hires, img_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_hires, bg_display = load_image(path_8bit, 500, 500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixasonics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
