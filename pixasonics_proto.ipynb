{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import signalflow as sf\n",
    "from IPython.display import Audio, display\n",
    "from pixasonics.core import App, Mapper\n",
    "from pixasonics.features import MeanPixelValue\n",
    "from pixasonics.synths import Theremin\n",
    "\n",
    "# Create app\n",
    "app = App()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image\n",
    "img_path = \"images/cellular_dataset/merged_8bit/Timepoint_005_220518-ST_C03_s1.jpg\"\n",
    "# img_path = \"images/test.jpg\"\n",
    "img = app.load_image_file(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.normalize_display = True\n",
    "app.normalize_display_global = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create objects\n",
    "mean_pix = MeanPixelValue()\n",
    "# mean_pix = MeanPixelValue(selected_channels=[0, 1]) # test selected channels\n",
    "# theremin = Theremin()\n",
    "theremin = Theremin(frequency=[440, 440, 440], panning=[-1, 1]) # test multichannel\n",
    "pix2freq = Mapper(mean_pix, theremin[\"frequency\"], exponent=2, out_high=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.attach_feature(mean_pix)\n",
    "app.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.synths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.attach_synth(theremin)\n",
    "app.synths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.attach_mapper(pix2freq)\n",
    "app.mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.detach_mapper(pix2freq)\n",
    "app.mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test adding another mapping: mean pixel value to amplitude with an exponential curve\n",
    "pix2amp = Mapper(mean_pix, theremin[\"amplitude\"], exponent=2)\n",
    "app.attach_mapper(pix2amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix2pan = Mapper(mean_pix, theremin[\"panning\"])\n",
    "app.attach_mapper(pix2pan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detach a mapper\n",
    "app.detach_mapper(pix2amp)\n",
    "app.mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detach old frequency mapping and add a new one with different scaling\n",
    "app.detach_mapper(pix2freq)\n",
    "pix2freq = Mapper(mean_pix, theremin[\"frequency\"], exponent=2, out_low=100, out_high=2000)\n",
    "app.attach_mapper(pix2freq)\n",
    "app.mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = sf.AudioGraph.get_shared_graph()\n",
    "print(graph.structure)\n",
    "print(graph.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Real-Time Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: horizontal scan\n",
    "duration = 5\n",
    "my_timeline = [\n",
    "    (0, {\n",
    "        \"probe_width\": 1,\n",
    "        \"probe_height\": 500,\n",
    "        \"probe_x\": 0,\n",
    "        \"probe_y\": 0\n",
    "    }),\n",
    "    (duration, {\n",
    "        \"probe_x\": 499\n",
    "    })\n",
    "]\n",
    "\n",
    "target_filename = \"horizontal_scan.wav\"\n",
    "\n",
    "app.render_timeline_to_file(my_timeline, target_filename)\n",
    "\n",
    "display(Audio(target_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: vertical scan\n",
    "duration = 5\n",
    "my_timeline = [\n",
    "    (0, {\n",
    "        \"probe_width\": 500,\n",
    "        \"probe_height\": 1,\n",
    "        \"probe_x\": 0,\n",
    "        \"probe_y\": 0\n",
    "    }),\n",
    "    (duration, {\n",
    "        \"probe_y\": 499\n",
    "    })\n",
    "]\n",
    "\n",
    "target_filename = \"vertical_scan.wav\"\n",
    "\n",
    "app.render_timeline_to_file(my_timeline, target_filename)\n",
    "\n",
    "display(Audio(target_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Array reading proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(100, 100, 20, 10)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels = [0, 2, 5, 9]\n",
    "b = a[:, :, selected_channels, :]\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(a, axis=(1, 2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_16bit = \"images/cellular_dataset/single_channel_16bit/Timepoint_005_220518-ST_C03_s1_w1.TIF\"\n",
    "img = Image.open(path_16bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_8bit = \"images/cellular_dataset/merged_8bit/Timepoint_005_220518-ST_C03_s1.jpg\"\n",
    "img = Image.open(path_8bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the image dimensions\n",
    "width, height = img.size\n",
    "# get image channels\n",
    "channels = len(img.getbands())\n",
    "width, height, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the image data type\n",
    "img.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img)\n",
    "img.shape, img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the image is not dtype=uint8,divide it by the max of the dtype and convert to uint8\n",
    "img = (img / np.iinfo(img.dtype).max * 255).astype(np.uint8)\n",
    "img.shape, img.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.iinfo(np.uint16).max, np.iinfo(np.uint8).max, np.finfo(np.float32).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the max of float32\n",
    "np.finfo(np.float32).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get whether the img is integer or float dtype\n",
    "is_int = np.issubdtype(img.dtype, np.integer)\n",
    "is_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, target_width, target_height):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((target_width, target_height))\n",
    "    img_hires = np.array(img)\n",
    "    if np.issubdtype(img_hires.dtype, np.integer):\n",
    "        img_display = (img_hires / np.iinfo(img_hires.dtype).max * 255).astype(np.uint8)\n",
    "    else:\n",
    "        img_display = (img_hires / np.finfo(img_hires.dtype).max * 255).astype(np.uint8)\n",
    "    return img_hires, img_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_hires, bg_display = load_image(path_8bit, 500, 500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixasonics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
