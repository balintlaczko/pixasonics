{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import signalflow as sf\n",
    "from PIL import Image\n",
    "from IPython.display import Audio, display\n",
    "from pixasonics.core import App, Mapper\n",
    "from pixasonics.features import *\n",
    "from pixasonics.synths import Theremin, Oscillator, FilteredNoise, SimpleFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create app\n",
    "app = App(image_size=(800, 800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all red-ch images into arrays and concatenate them in the channel dimension\n",
    "img_folder = \"images/cellular_dataset/single_channel_16bit/\"\n",
    "img_files = os.listdir(img_folder)\n",
    "img_files = [f for f in img_files if f.endswith(\"w2.TIF\")] # only red channel images\n",
    "imgs = []\n",
    "for img_file in img_files:\n",
    "    img_path = os.path.join(img_folder, img_file)\n",
    "    img = Image.open(img_path)\n",
    "    img = np.array(img)\n",
    "    imgs.append(img)\n",
    "img = np.stack(imgs, axis=-1) # now the last dimension is the channel dimension\n",
    "print(img.shape)\n",
    "app.load_image_data(img) # load as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use all images in the folder\n",
    "img_folder = \"images/cellular_dataset/single_channel_16bit/\"\n",
    "img_files = os.listdir(img_folder)\n",
    "imgs_red = [f for f in img_files if f.endswith(\"w2.TIF\")] # only red channel images\n",
    "imgs_green = [f for f in img_files if f.endswith(\"w1.TIF\")] # only green channel images\n",
    "imgs_blue = [f for f in img_files if f.endswith(\"w3.TIF\")] # only blue channel images\n",
    "imgs = []\n",
    "for img_red, img_green, img_blue in zip(imgs_red, imgs_green, imgs_blue):\n",
    "    img_path_red = os.path.join(img_folder, img_red)\n",
    "    img_path_green = os.path.join(img_folder, img_green)\n",
    "    img_path_blue = os.path.join(img_folder, img_blue)\n",
    "    img_red = Image.open(img_path_red)\n",
    "    img_green = Image.open(img_path_green)\n",
    "    img_blue = Image.open(img_path_blue)\n",
    "    img_red = np.array(img_red)\n",
    "    img_green = np.array(img_green)\n",
    "    img_blue = np.array(img_blue)\n",
    "    img = np.stack([img_red, img_green, img_blue], axis=-1) # now the last dimension is the channel dimension\n",
    "    imgs.append(img)\n",
    "img = np.stack(imgs, axis=-1) # now the last dimension is the layer dimension\n",
    "print(img.shape)\n",
    "app.load_image_data(img) # load as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixasonics.core import AppRegistry\n",
    "\n",
    "app_registry = AppRegistry()\n",
    "\n",
    "app_registry._apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app2 = App(image_size=(500, 500))\n",
    "img_path = \"images/test.jpg\"\n",
    "app2.load_image_file(img_path)\n",
    "mean_red2 = MeanChannelValue(filter_channels=0, name=\"MeanRed\")\n",
    "# attach the feature to the app\n",
    "app2.attach_feature(mean_red2)\n",
    "\n",
    "# create a Theremin, a simple sine wave synth that we will use to sonify the mean pixel value\n",
    "theremin2 = Theremin()\n",
    "# attach the Theremin to the app\n",
    "app2.attach_synth(theremin2)\n",
    "\n",
    "# create a Mapper that will map the mean red pixel value (within the Probe) to the frequency of the Theremin\n",
    "red2freq2 = Mapper(\n",
    "    mean_red2, \n",
    "    theremin2[\"frequency\"], \n",
    "    exponent=2, name=\"Red2Freq\") # cubic mapping curve for a more \"linear\" feel of frequency changes\n",
    "# attach the Mapper to the app\n",
    "app2.attach_mapper(red2freq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.graph.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signalflow as sf\n",
    "graph = sf.AudioGraph.get_shared_graph()\n",
    "print(graph is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signalflow as sf\n",
    "\n",
    "graph = None\n",
    "buf = sf.Buffer(1, 48000)\n",
    "\n",
    "class TestPatch(sf.Patch):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        param = self.add_input(\"param\")\n",
    "\n",
    "        out = param * sf.SineOscillator(440)\n",
    "        self.set_output(out)\n",
    "\n",
    "def create_audio_graph(nrt=False):\n",
    "    graph = sf.AudioGraph.get_shared_graph()\n",
    "    output_device = sf.AudioOut_Dummy(2) if nrt else None\n",
    "    if graph is not None:\n",
    "        graph.destroy()\n",
    "    graph = sf.AudioGraph(\n",
    "        start=True,\n",
    "        output_device=output_device)\n",
    "    my_patch = TestPatch()\n",
    "    my_patch.set_input(\"param\", 0.5)\n",
    "    graph.play(my_patch)\n",
    "    if nrt:\n",
    "        graph.render_to_buffer(buf)\n",
    "    graph.stop(my_patch)\n",
    "    return graph\n",
    "\n",
    "print(graph) # should be None\n",
    "\n",
    "graph = create_audio_graph(nrt=False)\n",
    "\n",
    "print(\"RT\", graph.status)\n",
    "\n",
    "graph = create_audio_graph(nrt=True)\n",
    "\n",
    "print(\"NRT\", graph.status)\n",
    "\n",
    "graph = create_audio_graph(nrt=False)\n",
    "\n",
    "print(\"RT2\", graph.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = App(image_size=(800, 800))\n",
    "app.load_image_file(\"images/cellular_dataset/merged_8bit/Timepoint_001_220518-ST_C03_s1.jpg\")\n",
    "\n",
    "mean_red = MeanChannelValue(filter_channels=0, name=\"MeanRed\")\n",
    "app.attach(mean_red)\n",
    "\n",
    "num_instances = 5\n",
    "\n",
    "for i in range(num_instances):\n",
    "    theremin = Theremin()\n",
    "    app.attach(theremin)\n",
    "\n",
    "    red2freq = Mapper(mean_red, theremin[\"frequency\"], exponent=2, name=f\"Red2Freq{i}\")\n",
    "    app.attach(red2freq)\n",
    "\n",
    "    red2amp = Mapper(mean_red, theremin[\"amplitude\"], exponent=1, name=f\"Red2Amp{i}\")\n",
    "    app.attach(red2amp)\n",
    "\n",
    "    red2pan = Mapper(mean_red, theremin[\"panning\"], exponent=1, name=f\"Red2Pan{i}\")\n",
    "    app.attach(red2pan)\n",
    "\n",
    "# app.interaction_mode = \"toggle\"\n",
    "# app.audio = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.output_buffer_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.output_buffer_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osc = Oscillator()\n",
    "app.attach(osc)\n",
    "\n",
    "fnoise = FilteredNoise()\n",
    "app.attach(fnoise)\n",
    "\n",
    "fm = SimpleFM()\n",
    "app.attach(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(app.mappers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test audio settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.audio = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.master_volume = -6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.recording = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.recording_path = \"hey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.master_envelope.attack = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test display settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.normalize_display = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.normalize_display_global = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.display_channel_offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.display_layer_offset = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test probe settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.probe_width = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.probe_height = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.probe_x = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.probe_y = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.interaction_mode = \"hold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.probe_follows_idle_mouse = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signalflow as sf\n",
    "graph = sf.AudioGraph.get_shared_graph()\n",
    "if graph is not None:\n",
    "    graph.destroy()\n",
    "graph = sf.AudioGraph(output_device=sf.AudioOut_Dummy(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signalflow as sf\n",
    "graph = sf.AudioGraph()\n",
    "\n",
    "class Synth(sf.Patch):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "class TestPatch(Synth):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        param = self.add_input(\"param\")\n",
    "\n",
    "        out = param * sf.SineOscillator(440)\n",
    "        self.set_output(out)\n",
    "\n",
    "patch = TestPatch()\n",
    "patch.set_input(\"param\", 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch.set_input(\"param\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph.structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the type of the patch object\n",
    "print(type(patch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(patch, Synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(patch, sf.Patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AudioGraph: The global audio graph has already been created. To create a new graph, call .destroy() first.\n"
     ]
    }
   ],
   "source": [
    "import signalflow as sf\n",
    "config = sf.AudioGraphConfig()\n",
    "config.output_buffer_size = 480\n",
    "graph = sf.AudioGraph(config)\n",
    "\n",
    "class TestPatch(sf.Patch):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        out = sf.SineOscillator(440)\n",
    "        self.set_output(out)\n",
    "\n",
    "patch = TestPatch()\n",
    "\n",
    "graph.play(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to play\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[miniaudio] Output device: MacBook Pro Speakers (48000Hz, buffer size 1024 samples, 2 channels)\n"
     ]
    }
   ],
   "source": [
    "graph.destroy()\n",
    "config = sf.AudioGraphConfig()\n",
    "config.output_buffer_size = 1024\n",
    "graph = sf.AudioGraph(config)\n",
    "print(\"About to play\") # still prints\n",
    "graph.play(patch) # will crash Kernel here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[miniaudio] Output device: MacBook Pro Speakers (48000Hz, buffer size 1024 samples, 2 channels)\n"
     ]
    }
   ],
   "source": [
    "graph.destroy()\n",
    "config = sf.AudioGraphConfig()\n",
    "config.output_buffer_size = 1024\n",
    "graph = sf.AudioGraph(config)\n",
    "patch = TestPatch() # create a new patch\n",
    "graph.play(patch) # this will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixasonics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
